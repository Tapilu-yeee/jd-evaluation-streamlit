import os
import json
import streamlit as st
import google.generativeai as genai
import docx

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# =========================
# STREAMLIT CONFIG
# =========================
st.set_page_config(page_title="ÄÃ¡nh giÃ¡ cÃ´ng viá»‡c PwC", layout="wide")
st.title("ğŸ“‹ ÄÃ¡nh giÃ¡ mÃ´ táº£ cÃ´ng viá»‡c theo 12 yáº¿u tá»‘ PwC")
st.markdown("HÃ£y táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c Ä‘á»ƒ Ä‘Æ°á»£c há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng.")

# =========================
# API KEY (KHÃ”NG HARDCODE)
# =========================
api_key = st.secrets.get("AIzaSyA8a7ZxHfZAls3B_giKA-FVGWCqkopl07U") or os.getenv("AIzaSyA8a7ZxHfZAls3B_giKA-FVGWCqkopl07U")
if not api_key:
    st.error("âŒ Thiáº¿u GOOGLE_API_KEY. VÃ o Streamlit Cloud â†’ Manage app â†’ Settings â†’ Secrets vÃ  thÃªm GOOGLE_API_KEY.")
    st.stop()

genai.configure(api_key=api_key)

# =========================
# LOAD DATA / PROMPT (CACHE)
# =========================
@st.cache_data
def load_reference_data():
    with open("historical_evaluations.json", "r", encoding="utf-8") as f:
        return json.load(f)

@st.cache_data
def load_pwc_prompt():
    with open("pwc_prompt.txt", "r", encoding="utf-8") as f:
        return f.read()

REFERENCE_JD_EVALS = load_reference_data()
PWC_PROMPT = load_pwc_prompt()

# =========================
# CACHE MODEL (TRÃNH KHá»I Táº O Láº I)
# =========================
@st.cache_resource
def get_model():
    return genai.GenerativeModel("gemini-2.0-flash")

model = get_model()

# =========================
# FILE READERS
# =========================
def read_docx(file):
    d = docx.Document(file)
    return "\n".join([p.text for p in d.paragraphs if p.text.strip()])

def read_txt(file):
    return file.read().decode("utf-8", errors="ignore")

# =========================
# TF-IDF INDEX (CACHE) -> TÄ‚NG Tá»C find_similar_jd
# =========================
@st.cache_resource
def build_tfidf_index(reference_evals):
    # Giá»¯ logic nhÆ° báº¡n Ä‘ang lÃ m: corpus lÃ  job_title
    titles = [e.get("job_title", "") for e in reference_evals]
    vectorizer = TfidfVectorizer()
    ref_vecs = vectorizer.fit_transform(titles)
    return vectorizer, ref_vecs

def find_similar_jd(new_jd_text, reference_evals, top_k=5):
    vectorizer, ref_vecs = build_tfidf_index(reference_evals)
    new_vec = vectorizer.transform([new_jd_text])
    sim = cosine_similarity(new_vec, ref_vecs)[0]
    top_indices = sim.argsort()[-top_k:][::-1]
    return [reference_evals[i] for i in top_indices]

# =========================
# UI INPUTS
# =========================
job_title = st.text_input("ğŸ”¤ Nháº­p tÃªn vá»‹ trÃ­ cÃ´ng viá»‡c:")
uploaded_file = st.file_uploader("ğŸ“ Táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c (.docx hoáº·c .txt)", type=["docx", "txt"])

# Chá»‘ng gá»i láº·p do rerun
if "is_running" not in st.session_state:
    st.session_state.is_running = False

run_btn = st.button("ğŸš€ Evaluate JD", disabled=st.session_state.is_running)

# =========================
# MAIN RUN
# =========================
if run_btn:
    if not uploaded_file or not job_title:
        st.warning("Vui lÃ²ng nháº­p tÃªn vá»‹ trÃ­ vÃ  táº£i lÃªn file JD trÆ°á»›c khi Evaluate.")
        st.stop()

    st.session_state.is_running = True
    try:
        with st.spinner("ğŸ” Äang phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡..."):
            # 1) Read JD
            if uploaded_file.name.lower().endswith(".docx"):
                jd_content = read_docx(uploaded_file)
            else:
                jd_content = read_txt(uploaded_file)

            jd_content = (jd_content or "").strip()
            if not jd_content:
                st.error("File JD rá»—ng hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c ná»™i dung.")
                st.stop()

            # 2) Similar cases (TF-IDF cached)
            similar_cases = find_similar_jd(jd_content, REFERENCE_JD_EVALS, top_k=5)
            reference_context = "\n".join([
                f"{case.get('job_title','(no title)')}: {json.dumps(case.get('factors', {}), ensure_ascii=False)}"
                for case in similar_cases
            ])

            # 3) Build FINAL prompt (CHá»ˆ 1 Láº¦N Gá»ŒI API â€” bá» call thá»«a)
            prompt = f"""
{PWC_PROMPT}

DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c máº«u JD Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ theo phÆ°Æ¡ng phÃ¡p PwC:

{reference_context}

HÃ£y Ä‘Ã¡nh giÃ¡ JD má»›i theo chuáº©n PwC (12 yáº¿u tá»‘, xáº¿p loáº¡i tá»« A â†’ J).
Tráº£ káº¿t quáº£ á»Ÿ dáº¡ng báº£ng.
---

TÃªn vá»‹ trÃ­: {job_title}

JD má»›i:
{jd_content}
""".strip()

            # 4) Call Gemini (1 láº§n)
            response = model.generate_content(prompt)
            result = getattr(response, "text", "") or ""

            st.markdown("### âœ… Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ theo 12 yáº¿u tá»‘ PwC")
            st.markdown(result)

            # 5) Save history for later comparison (nhanh)
            if "jd_history" not in st.session_state:
                st.session_state.jd_history = []
            st.session_state.jd_history.append({
                "position": job_title,
                "content": jd_content
            })

    except Exception as e:
        st.error(f"âŒ Error: {e}")
    finally:
        st.session_state.is_running = False

# =========================
# OPTIONAL: COMPARE SCOPE (TÃCH NÃšT RIÃŠNG Äá»‚ KHÃ”NG LÃ€M CHáº¬M ÄÃNH GIÃ)
# =========================
if "jd_history" in st.session_state and len(st.session_state.jd_history) > 1:
    st.markdown("### ğŸ”„ So sÃ¡nh pháº¡m vi cÃ´ng viá»‡c vá»›i cÃ¡c vá»‹ trÃ­ trÆ°á»›c Ä‘Ã³")
    if st.button("So sÃ¡nh scope (cÃ³ thá»ƒ máº¥t thá»i gian)"):
        with st.spinner("Äang so sÃ¡nh scope..."):
            current = st.session_state.jd_history[-1]
            compare_prompt = (
                "HÃ£y so sÃ¡nh pháº¡m vi cÃ´ng viá»‡c (scope) cá»§a mÃ´ táº£ sau vá»›i nhá»¯ng mÃ´ táº£ Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ­ch trÆ°á»›c Ä‘Ã³.\n\n"
                f"JD má»›i ({current['position']}):\n{current['content']}\n\n"
            )
            for past in st.session_state.jd_history[:-1]:
                compare_prompt += f"\n---\nJD Ä‘Ã£ Ä‘Ã¡nh giÃ¡ ({past['position']}):\n{past['content']}\n"

            compare_prompt += "\n\nÄÆ°a ra cÃ¡c vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»“ng, má»©c Ä‘á»™ giá»‘ng nhau Æ°á»›c lÆ°á»£ng theo %, vÃ  lÃ½ do tÆ°Æ¡ng Ä‘á»“ng."

            compare_response = model.generate_content(compare_prompt)
            st.markdown(getattr(compare_response, "text", ""))

