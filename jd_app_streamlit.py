import os
import time
import json
import streamlit as st
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import docx

# =========================
# STREAMLIT CONFIG
# =========================
st.set_page_config(page_title="ÄÃ¡nh giÃ¡ cÃ´ng viá»‡c PwC", layout="wide")
st.title("ğŸ“‹ ÄÃ¡nh giÃ¡ mÃ´ táº£ cÃ´ng viá»‡c theo 12 yáº¿u tá»‘ PwC")
st.markdown("HÃ£y táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c Ä‘á»ƒ Ä‘Æ°á»£c há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng.")

# =========================
# API KEY (FIX: KHÃ”NG HARDCODE)
# =========================
api_key = st.secrets.get("AIzaSyALIFJZAmvuu5G5QVOMjp0bXb7sn-Hhfh4") or os.getenv("AIzaSyALIFJZAmvuu5G5QVOMjp0bXb7sn-Hhfh4")
if not api_key:
    st.error("âŒ Thiáº¿u GOOGLE_API_KEY. HÃ£y vÃ o Streamlit Cloud â†’ Manage app â†’ Settings â†’ Secrets vÃ  thÃªm GOOGLE_API_KEY.")
    st.stop()

genai.configure(api_key=api_key)

# Model: báº¡n Ä‘ang dÃ¹ng gemini-2.0-flash, ok
model = genai.GenerativeModel("gemini-2.0-flash")

# =========================
# HELPERS: RETRY + TRIM (FIX ResourceExhausted)
# =========================
MAX_JD_CHARS = 25000          # cáº¯t JD Ä‘á»ƒ trÃ¡nh token quÃ¡ lá»›n
MAX_REF_CONTEXT_CHARS = 12000 # giá»›i háº¡n pháº§n reference_context Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i

def safe_trim(text: str, max_chars: int) -> str:
    text = text or ""
    return text[:max_chars]

def call_gemini_with_retry(prompt: str, retries: int = 4):
    """Retry theo backoff khi gáº·p ResourceExhausted (quota/rate limit)."""
    last_err = None
    for i in range(retries):
        try:
            return model.generate_content(prompt)
        except ResourceExhausted as e:
            last_err = e
            time.sleep(2 ** i)  # 1s,2s,4s,8s
    raise last_err

# =========================
# LOAD FILES
# =========================
@st.cache_data
def load_reference_data():
    with open("historical_evaluations.json", "r", encoding="utf-8") as f:
        return json.load(f)

REFERENCE_JD_EVALS = load_reference_data()

@st.cache_data
def load_pwc_prompt():
    with open("pwc_prompt.txt", "r", encoding="utf-8") as f:
        return f.read()

def read_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs if para.text.strip() != ""])

def read_txt(file):
    return file.read().decode("utf-8", errors="ignore")

def find_similar_jd(new_jd_text, reference_evals, top_k=5):
    # NOTE: code cá»§a báº¡n Ä‘ang dÃ¹ng e["job_title"] lÃ m corpus, mÃ¬nh giá»¯ nguyÃªn logic,
    # nhÆ°ng náº¿u báº¡n muá»‘n similarity theo ná»™i dung JD thÃ¬ cáº§n Ä‘á»•i sang e["jd_content"] (náº¿u cÃ³).
    corpus = [e["job_title"] for e in reference_evals] + [new_jd_text]
    vec = TfidfVectorizer().fit_transform(corpus)
    sim_matrix = cosine_similarity(vec[-1], vec[:-1])
    top_indices = sim_matrix[0].argsort()[-top_k:][::-1]
    return [reference_evals[i] for i in top_indices]

# =========================
# UI INPUTS
# =========================
job_title = st.text_input("ğŸ”¤ Nháº­p tÃªn vá»‹ trÃ­ cÃ´ng viá»‡c:")
uploaded_file = st.file_uploader("ğŸ“ Táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c (.docx hoáº·c .txt)", type=["docx", "txt"])

# =========================
# ANTI-RERUN LOCK (FIX gá»i API láº·p)
# =========================
if "is_running" not in st.session_state:
    st.session_state.is_running = False

# NÃºt báº¥m Ä‘á»ƒ trÃ¡nh auto-run khi nháº­p text/upload (giáº£m gá»i API ngoÃ i Ã½ muá»‘n)
run_btn = st.button("ğŸš€ Evaluate JD", disabled=st.session_state.is_running)

if run_btn:
    if not uploaded_file or not job_title:
        st.warning("Vui lÃ²ng nháº­p tÃªn vá»‹ trÃ­ vÃ  táº£i lÃªn file JD trÆ°á»›c khi Evaluate.")
        st.stop()

    st.session_state.is_running = True
    try:
        with st.spinner("ğŸ” Äang phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡..."):
            # ---- Read JD (fix txt/docx)
            if uploaded_file.name.lower().endswith(".docx"):
                jd_content = read_docx(uploaded_file)
            else:
                jd_content = read_txt(uploaded_file)

            jd_content = jd_content.strip()
            if not jd_content:
                st.error("File JD rá»—ng hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c ná»™i dung.")
                st.stop()

            # ---- Trim JD Ä‘á»ƒ trÃ¡nh prompt quÃ¡ dÃ i
            if len(jd_content) > MAX_JD_CHARS:
                st.warning(f"JD dÃ i ({len(jd_content)} kÃ½ tá»±). ÄÃ£ tá»± cáº¯t cÃ²n {MAX_JD_CHARS} kÃ½ tá»± Ä‘á»ƒ trÃ¡nh vÆ°á»£t giá»›i háº¡n token.")
            jd_for_prompt = safe_trim(jd_content, MAX_JD_CHARS)

            # ---- Find similar cases
            similar_cases = find_similar_jd(jd_for_prompt, REFERENCE_JD_EVALS, top_k=5)
            reference_context = "\n".join([
                f"{case.get('job_title','(no title)')}: {json.dumps(case.get('factors', {}), ensure_ascii=False)}"
                for case in similar_cases
            ])
            reference_context = safe_trim(reference_context, MAX_REF_CONTEXT_CHARS)

            pwc_prompt = load_pwc_prompt()

            # ---- ONE SINGLE prompt (fix: báº¡n Ä‘ang gá»i generate_content 2 láº§n, láº§n Ä‘áº§u bá»‹ thá»«a)
            prompt = f"""
{pwc_prompt}

DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c máº«u JD Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ theo phÆ°Æ¡ng phÃ¡p PwC:

{reference_context}

HÃ£y Ä‘Ã¡nh giÃ¡ JD má»›i theo chuáº©n PwC (12 yáº¿u tá»‘, xáº¿p loáº¡i tá»« A â†’ J).
Tráº£ káº¿t quáº£ á»Ÿ dáº¡ng báº£ng.
Náº¿u JD thiáº¿u thÃ´ng tin, hÃ£y ghi rÃµ "Thiáº¿u dá»¯ liá»‡u" á»Ÿ yáº¿u tá»‘ tÆ°Æ¡ng á»©ng vÃ  nÃªu giáº£ Ä‘á»‹nh tá»‘i thiá»ƒu.

---

TÃªn vá»‹ trÃ­: {job_title}

JD má»›i:
{jd_for_prompt}
""".strip()

            # ---- Call Gemini with retry
            response = call_gemini_with_retry(prompt, retries=4)
            result = getattr(response, "text", "") or ""
            st.markdown("### âœ… Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ theo 12 yáº¿u tá»‘ PwC")
            st.markdown(result)

            # ---- LÆ°u lá»‹ch sá»­ Ä‘á»ƒ so sÃ¡nh scope
            if "jd_history" not in st.session_state:
                st.session_state.jd_history = []
            st.session_state.jd_history.append({
                "position": job_title,
                "content": jd_for_prompt
            })

            # ---- Compare scope (cÅ©ng cÃ³ thá»ƒ tá»‘n token -> trim + retry)
            if len(st.session_state.jd_history) > 1:
                st.markdown("### ğŸ”„ So sÃ¡nh pháº¡m vi cÃ´ng viá»‡c vá»›i cÃ¡c vá»‹ trÃ­ trÆ°á»›c Ä‘Ã³")

                compare_prompt = (
                    "HÃ£y so sÃ¡nh pháº¡m vi cÃ´ng viá»‡c (scope) cá»§a mÃ´ táº£ sau vá»›i nhá»¯ng mÃ´ táº£ Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ­ch trÆ°á»›c Ä‘Ã³.\n\n"
                    f"JD má»›i ({job_title}):\n{jd_for_prompt}\n\n"
                )
                for past in st.session_state.jd_history[:-1]:
                    compare_prompt += f"\n---\nJD Ä‘Ã£ Ä‘Ã¡nh giÃ¡ ({past['position']}):\n{safe_trim(past['content'], 12000)}\n"

                compare_prompt += "\n\nÄÆ°a ra cÃ¡c vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»“ng, má»©c Ä‘á»™ giá»‘ng nhau Æ°á»›c lÆ°á»£ng theo %, vÃ  lÃ½ do tÆ°Æ¡ng Ä‘á»“ng."

                # Trim toÃ n prompt compare Ä‘á»ƒ trÃ¡nh quÃ¡ dÃ i
                compare_prompt = safe_trim(compare_prompt, 35000)

                compare_response = call_gemini_with_retry(compare_prompt, retries=4)
                st.markdown(getattr(compare_response, "text", ""))

    except ResourceExhausted:
        st.error(
            "âŒ ResourceExhausted: Báº¡n Ä‘ang vÆ°á»£t quota/rate limit hoáº·c prompt quÃ¡ lá»›n.\n\n"
            "Gá»£i Ã½: thá»­ láº¡i sau 1â€“2 phÃºt, giáº£m Ä‘á»™ dÃ i JD, hoáº·c tÄƒng quota/billing cho project."
        )
    except Exception as e:
        st.error(f"âŒ Error: {e}")
    finally:
        st.session_state.is_running = False
