import streamlit as st
import google.generativeai as genai
import docx
import os

# Cáº¥u hÃ¬nh Gemini API
api_key = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)

# HÃ m Ä‘á»c ná»™i dung tá»« file .docx
def read_docx(file):
    doc = docx.Document(file)
    return "\n".join([para.text for para in doc.paragraphs if para.text.strip() != ""])

# Load prompt phÆ°Æ¡ng phÃ¡p PwC tá»« file
@st.cache_data
def load_pwc_prompt():
    with open("pwc_prompt.txt", "r", encoding="utf-8") as f:
        return f.read()

# Khá»Ÿi táº¡o model Gemini
model = genai.GenerativeModel("gemini-pro")

# Giao diá»‡n chÃ­nh
st.set_page_config(page_title="ÄÃ¡nh giÃ¡ cÃ´ng viá»‡c PwC", layout="wide")
st.title("ğŸ“‹ ÄÃ¡nh giÃ¡ mÃ´ táº£ cÃ´ng viá»‡c theo 12 yáº¿u tá»‘ PwC")
st.markdown("HÃ£y táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c (.docx) Ä‘á»ƒ Ä‘Æ°á»£c há»‡ thá»‘ng AI Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng.")

# Nháº­p tÃªn vá»‹ trÃ­
job_title = st.text_input("ğŸ”¤ Nháº­p tÃªn vá»‹ trÃ­ cÃ´ng viá»‡c:")

# Upload file .docx
uploaded_file = st.file_uploader("ğŸ“ Táº£i lÃªn file mÃ´ táº£ cÃ´ng viá»‡c (.docx)", type=["docx"])

# Xá»­ lÃ½ khi cÃ³ file vÃ  tÃªn vá»‹ trÃ­
if uploaded_file and job_title:
    with st.spinner("ğŸ” Äang phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡..."):
        jd_content = read_docx(uploaded_file)
        prompt = load_pwc_prompt() + f"\n\nÄÃ¢y lÃ  mÃ´ táº£ cÃ´ng viá»‡c cá»§a vá»‹ trÃ­: {job_title}\n\n{jd_content}"
        response = model.generate_content(prompt)
        result = response.text

        # Hiá»ƒn thá»‹ káº¿t quáº£ Ä‘Ã¡nh giÃ¡
        st.markdown("### âœ… Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ theo 12 yáº¿u tá»‘ PwC")
        st.markdown(result)

        # LÆ°u vÃ o lá»‹ch sá»­ Ä‘á»ƒ so sÃ¡nh
        if "jd_history" not in st.session_state:
            st.session_state.jd_history = []
        st.session_state.jd_history.append({
            "position": job_title,
            "content": jd_content
        })

        # So sÃ¡nh vá»›i cÃ¡c JD trÆ°á»›c Ä‘Ã³ náº¿u cÃ³
        if len(st.session_state.jd_history) > 1:
            st.markdown("### ğŸ”„ So sÃ¡nh pháº¡m vi cÃ´ng viá»‡c vá»›i cÃ¡c vá»‹ trÃ­ trÆ°á»›c Ä‘Ã³")

            compare_prompt = (
                "HÃ£y so sÃ¡nh pháº¡m vi cÃ´ng viá»‡c (scope) cá»§a mÃ´ táº£ sau vá»›i nhá»¯ng mÃ´ táº£ Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n tÃ­ch trÆ°á»›c Ä‘Ã³.\n\n"
                f"JD má»›i ({job_title}):\n{jd_content}\n\n"
            )
            for past in st.session_state.jd_history[:-1]:
                compare_prompt += f"\n---\nJD Ä‘Ã£ Ä‘Ã¡nh giÃ¡ ({past['position']}):\n{past['content']}\n"

            compare_prompt += (
                "\n\nÄÆ°a ra cÃ¡c vá»‹ trÃ­ tÆ°Æ¡ng Ä‘á»“ng, má»©c Ä‘á»™ giá»‘ng nhau Æ°á»›c lÆ°á»£ng theo %, vÃ  lÃ½ do tÆ°Æ¡ng Ä‘á»“ng."
            )

            compare_response = model.generate_content(compare_prompt)
            st.markdown(compare_response.text)
